name: Zhihu Scrape (Playwright)

on:
  workflow_dispatch: {}
  schedule:
    - cron: "0 0 * * *"

permissions:
  contents: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install playwright pandas
          fi

      - name: Install Playwright browsers
        run: |
          python -m playwright install --with-deps chromium

      - name: Restore storage_state.json from Secret "storage"
        env:
          STORAGE_JSON: ${{ secrets.storage }}
        run: |
          python - << 'PY'
          import os
          s = os.environ.get("STORAGE_JSON", "")
          if not s.strip():
            raise SystemExit("Missing secret: storage")
          with open("storage_state.json", "w", encoding="utf-8") as f:
            f.write(s)
          print("storage_state.json restored in repo root")
          PY

      - name: Copy storage_state.json into scripts/ (compat)
        run: |
          cp storage_state.json scripts/storage_state.json || true

      - name: Run scraper (scripts/zhihu.py)
        env:
          KEYWORDS: "王飞跃,自动化学会"
          MAX_RESULTS_PER_KEYWORD: "30"
          HEADLESS: "true"
          GOTO_TIMEOUT_MS: "180000"
          GOTO_RETRIES: "3"
        run: |
          python scripts/zhihu.py

      - name: Build data/zhihu_data.json and data/meta.json for website
        env:
          KEYWORDS: "王飞跃,自动化学会"
        run: |
          python - << 'PY'
          import json, os
          from pathlib import Path
          import pandas as pd
          import datetime

          data_dir = Path("data")
          data_dir.mkdir(exist_ok=True)

          # 优先用固定文件名；如果不存在就找 data/ 下最新 csv
          csv_path = data_dir / "zhihu_data.csv"
          if not csv_path.exists():
              csvs = sorted(data_dir.glob("*.csv"), key=lambda p: p.stat().st_mtime, reverse=True)
              if not csvs:
                  print("No CSV found in data/. Skip building JSON/meta.")
                  raise SystemExit(0)
              csv_path = csvs[0]
              # 统一复制成固定名，保持你原来的目录结构
              fixed = data_dir / "zhihu_data.csv"
              if csv_path.name != fixed.name:
                  fixed.write_bytes(csv_path.read_bytes())
                  csv_path = fixed

          df = pd.read_csv(csv_path)

          # 输出网页读取的 JSON
          out_json = data_dir / "zhihu_data.json"
          out_json.write_text(df.to_json(orient="records", force_ascii=False), encoding="utf-8")
          print("Wrote", out_json)

          # 输出网页读取的 meta.json
          kw = os.getenv("KEYWORDS", "")
          keywords = [x.strip() for x in kw.replace("，", ",").split(",") if x.strip()]
          meta = {
              "updated_at": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
              "keywords": keywords,
              "count": int(len(df)),
          }
          meta_path = data_dir / "meta.json"
          meta_path.write_text(json.dumps(meta, ensure_ascii=False, indent=2), encoding="utf-8")
          print("Wrote", meta_path)
          PY

      - name: Commit and push updated data (csv/json/meta)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git add data/zhihu_data.csv data/zhihu_data.json data/meta.json || true

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "update zhihu data"
          git push

      - name: Upload artifacts (debug)
        uses: actions/upload-artifact@v4
        with:
          name: zhihu-output
          path: |
            data/
            debug/
          if-no-files-found: warn
