name: scrape-zhihu

on:
  workflow_dispatch:
  schedule:
    # GitHub Actions 用 UTC
    # 例如：洛杉矶时间 10:00（冬令时 UTC-8）≈ 18:00 UTC → "0 18 * * *"
    - cron: "0 18 * * *"

permissions:
  contents: write

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install playwright pandas
          python -m playwright install --with-deps chromium

      # （可选）如果你需要登录态：把 storage_state.json 的 base64 放到 GitHub Secrets
      # Secret 名字：ZHIHU_STORAGE_STATE_B64
      - name: Restore storage_state.json (optional)
        env:
          ZHIHU_STORAGE_STATE_B64: ${{ secrets.ZHIHU_STORAGE_STATE_B64 }}
        run: |
          if [ -n "$ZHIHU_STORAGE_STATE_B64" ]; then
            echo "$ZHIHU_STORAGE_STATE_B64" | base64 -d > storage_state.json
            echo "storage_state.json restored"
          else
            echo "No storage state provided"
          fi

      - name: Run scraper
        env:
          KEYWORDS: '["王飞跃","自动化学会"]'
          MAX_RESULTS_PER_KEYWORD: "50"
          HEADLESS: "true"
        run: |
          mkdir -p data
          python scripts/zhihu_scrape_once.py

      - name: Commit data
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/*.json data/*.csv || true
          git commit -m "update zhihu data" || echo "No changes"
          git push
